{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc663572",
   "metadata": {},
   "source": [
    "# Augment and downscale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fdcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38ac04",
   "metadata": {},
   "source": [
    "## Data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3742c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_folder(path):\n",
    "    path = pathlib.Path(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = pathlib.Path('../../data/')\n",
    "rid_path = data_path / 'RID'\n",
    "input_path = rid_path / 'input'\n",
    "output_path = rid_path / 'output'\n",
    "\n",
    "# Roooftop processed and split data paths\n",
    "segment_dataset_path = output_path / 'masks_segments_reviewed'\n",
    "segment_train_path = segment_dataset_path / 'train'\n",
    "segment_train_image_path = segment_train_path / 'image'\n",
    "segment_train_label_path = segment_train_path / 'label'\n",
    "segment_valz19_path = segment_dataset_path / 'val_z19'\n",
    "segment_valz19_image_path = segment_valz19_path / 'image'\n",
    "create_clean_folder(segment_valz19_image_path)\n",
    "segment_valz19_label_path = segment_valz19_path / 'label'\n",
    "create_clean_folder(segment_valz19_label_path)\n",
    "\n",
    "# Rooftop augmented data paths\n",
    "segment_aug_dataset_path = output_path / 'masks_segments_reviewed_aug'\n",
    "segment_aug_train_path = segment_aug_dataset_path / 'train'\n",
    "segment_aug_train_image_path = segment_aug_train_path / 'image'\n",
    "create_clean_folder(segment_aug_train_image_path)\n",
    "segment_aug_train_label_path = segment_aug_train_path / 'label'\n",
    "create_clean_folder(segment_aug_train_label_path)\n",
    "\n",
    "# Superstructure rocessed and split data paths\n",
    "superstructures_dataset_path = output_path / 'masks_superstructures_reviewed'\n",
    "superstructures_train_path = superstructures_dataset_path / 'train'\n",
    "superstructures_train_image_path = superstructures_train_path / 'image'\n",
    "superstructures_train_label_path = superstructures_train_path / 'label'\n",
    "\n",
    "# Superstructure augmented data paths\n",
    "superstructures_aug_dataset_path = output_path / 'masks_superstructures_reviewed_aug'\n",
    "superstructures_aug_train_path = superstructures_aug_dataset_path / 'train'\n",
    "superstructures_aug_train_image_path = superstructures_aug_train_path / 'image'\n",
    "create_clean_folder(superstructures_aug_train_image_path)\n",
    "superstructures_aug_train_label_path = superstructures_aug_train_path / 'label'\n",
    "create_clean_folder(superstructures_aug_train_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a8c7e",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Transformations performed:\n",
    "\n",
    "- Multiplying the sample data by a factor defined by AUGMENT_FACTOR\n",
    "- Concatenate 4 images into one and resize them to downscale from 10cm/pixel to 20cm/pixel\n",
    "- Randomly rotate by 0, 90, 180 or 270 degrees\n",
    "- Randomly perform an average filter\n",
    "- Randomly flip horizontally\n",
    "- Randomly flip vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_list_float(l, factor):\n",
    "    factor_int = int(factor)\n",
    "    out = l * factor_int\n",
    "    diff = factor - factor_int\n",
    "    diff_len = int(diff * len(l))\n",
    "    \n",
    "    return out + l[:diff_len]\n",
    "\n",
    "def concat_images(img1, img2, img3, img4, rescaling_factor=0.5):\n",
    "    img_v = cv2.vconcat([img1, img2])\n",
    "    img_h = cv2.vconcat([img3, img4])\n",
    "    img = cv2.hconcat([img_v, img_h])\n",
    "    \n",
    "    return cv2.resize(img, (0,0), fx=rescaling_factor, fy=rescaling_factor)\n",
    "\n",
    "def process_pair(img, mask, correct):\n",
    "    # Randomly rotate by a multiply of 90, and correct pixels by corresponding value\n",
    "    rotations = {\n",
    "        None: 0,\n",
    "        cv2.ROTATE_90_CLOCKWISE: 4,\n",
    "        cv2.ROTATE_180: 8,\n",
    "        cv2.ROTATE_90_COUNTERCLOCKWISE: 12\n",
    "    }\n",
    "    rotation, correction = random.choice(list(rotations.items()))\n",
    "    \n",
    "    if rotation:\n",
    "        img = cv2.rotate(img, rotation)\n",
    "        mask = cv2.rotate(mask, rotation)\n",
    "\n",
    "    if correct:\n",
    "        corrected = (mask + correction) % 16\n",
    "        filtered = mask>16\n",
    "        # where mask is greater than 16, keep the original mask, otherwise correct\n",
    "        mask = np.where(filtered, mask, corrected)\n",
    "    \n",
    "    # Random average filtering every other image\n",
    "    avg_filter = random.uniform(0, 1)\n",
    "    if avg_filter > 0.5:\n",
    "        kernel = np.ones((5,5),np.float32) / random.randrange(15,30)\n",
    "        img = cv2.filter2D(img,-1,kernel)\n",
    "    \n",
    "    # Flip vertically every other image\n",
    "    flip_filter = random.uniform(0, 1)\n",
    "    if flip_filter:\n",
    "        if correct:\n",
    "            mask_tmp = np.copy(mask)\n",
    "            mask_tmp[mask == 0] = 8\n",
    "            mask_tmp[mask == 8] = 0\n",
    "            mask_tmp[mask == 1] = 7\n",
    "            mask_tmp[mask == 7] = 1\n",
    "            mask_tmp[mask == 2] = 6\n",
    "            mask_tmp[mask == 6] = 2\n",
    "            mask_tmp[mask == 3] = 5\n",
    "            mask_tmp[mask == 5] = 3\n",
    "            mask_tmp[mask == 9] = 15\n",
    "            mask_tmp[mask == 15] = 9\n",
    "            mask_tmp[mask == 10] = 14\n",
    "            mask_tmp[mask == 14] = 10\n",
    "            mask_tmp[mask == 11] = 13\n",
    "            mask_tmp[mask == 13] = 11\n",
    "            mask = mask_tmp\n",
    "        mask = cv2.flip(mask, 0)\n",
    "        img = cv2.flip(img, 0)\n",
    "        \n",
    "    # Flip horizontally every other image\n",
    "    flip_filter = random.uniform(0, 1)\n",
    "    if flip_filter:\n",
    "        if correct:\n",
    "            mask_tmp = np.copy(mask)\n",
    "            mask_tmp[mask == 1] = 15\n",
    "            mask_tmp[mask == 15] = 1\n",
    "            mask_tmp[mask == 2] = 14\n",
    "            mask_tmp[mask == 14] = 2\n",
    "            mask_tmp[mask == 3] = 13\n",
    "            mask_tmp[mask == 13] = 3\n",
    "            mask_tmp[mask == 4] = 12\n",
    "            mask_tmp[mask == 12] = 4\n",
    "            mask_tmp[mask == 5] = 11\n",
    "            mask_tmp[mask == 11] = 5\n",
    "            mask_tmp[mask == 6] = 10\n",
    "            mask_tmp[mask == 10] = 6\n",
    "            mask_tmp[mask == 7] = 9\n",
    "            mask_tmp[mask == 9] = 7\n",
    "            mask = mask_tmp\n",
    "        mask = cv2.flip(mask, 1)\n",
    "        img = cv2.flip(img, 1)\n",
    "    \n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f910a",
   "metadata": {},
   "source": [
    "## Processing Rooftop images at original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c985d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1504/1504 [01:56<00:00, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy original images and randomly transform them\n",
    "path_list = list(segment_train_image_path.glob('*.png'))\n",
    "random.shuffle(path_list)\n",
    "\n",
    "for path in tqdm(path_list):\n",
    "    name = path.name\n",
    "    img = cv2.imread(str(segment_train_image_path / name))\n",
    "    mask = cv2.imread(str(segment_train_label_path / name))\n",
    "\n",
    "    cv2.imwrite(str(segment_aug_train_image_path / name), img)\n",
    "    cv2.imwrite(str(segment_aug_train_label_path / name), mask)\n",
    "    \n",
    "    img, mask = process_pair(img, mask, correct=True)\n",
    "    \n",
    "    cv2.imwrite(str(segment_aug_train_image_path / name.replace('.png', '_transform.png')), img)\n",
    "    cv2.imwrite(str(segment_aug_train_label_path / name.replace('.png', '_transform.png')), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0d854",
   "metadata": {},
   "source": [
    "## Processing Rooftop images at half size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a494c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 3008/3008 [04:40<00:00, 10.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Factor to augment the data, or how much to increase the original dataset\n",
    "AUGMENT_FACTOR = 8\n",
    "path_list = list(segment_train_image_path.glob('*.png'))\n",
    "path_list = multiply_list_float(path_list, AUGMENT_FACTOR)\n",
    "\n",
    "# Iterate every 4 images to get also lower resolution images\n",
    "for i in tqdm(range(0, len(path_list), 4)):\n",
    "    name_1 = path_list[i].name\n",
    "    name_2 = path_list[i+1].name\n",
    "    name_3 = path_list[i+2].name\n",
    "    name_4 = path_list[i+3].name\n",
    "    \n",
    "    img_1 = cv2.imread(str(segment_train_image_path / name_1))\n",
    "    img_2 = cv2.imread(str(segment_train_image_path / name_2))\n",
    "    img_3 = cv2.imread(str(segment_train_image_path / name_3))\n",
    "    img_4 = cv2.imread(str(segment_train_image_path / name_4))\n",
    "    mask_1 = cv2.imread(str(segment_train_label_path / name_1))\n",
    "    mask_2 = cv2.imread(str(segment_train_label_path / name_2))\n",
    "    mask_3 = cv2.imread(str(segment_train_label_path / name_3))\n",
    "    mask_4 = cv2.imread(str(segment_train_label_path / name_4))\n",
    "    \n",
    "    img = concat_images(img_1, img_2, img_3, img_4, 0.5)\n",
    "    mask = concat_images(mask_1, mask_2, mask_3, mask_4, 0.5)\n",
    "\n",
    "    # For z19 training validation\n",
    "    cv2.imwrite(str(segment_valz19_image_path / (str(i) + '_concat.png')), img)\n",
    "    cv2.imwrite(str(segment_valz19_label_path / (str(i) + '_concat.png')), mask)\n",
    "\n",
    "    cv2.imwrite(str(segment_aug_train_image_path / (str(i) + '_concat.png')), img)\n",
    "    cv2.imwrite(str(segment_aug_train_label_path / (str(i) + '_concat.png')), mask)\n",
    "    \n",
    "    img, mask = process_pair(img, mask, correct=True)\n",
    "    \n",
    "    cv2.imwrite(str(segment_aug_train_image_path / (str(i) + '_concat_transform.png')), img)\n",
    "    cv2.imwrite(str(segment_aug_train_label_path / (str(i) + '_concat_transform.png')), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48e8c0",
   "metadata": {},
   "source": [
    "## Processing Superstructure images at original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843af05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1504/1504 [01:30<00:00, 16.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy original images and randomly transform them\n",
    "path_list = list(superstructures_train_image_path.glob('*.png'))\n",
    "random.shuffle(path_list)\n",
    "\n",
    "for path in tqdm(path_list):\n",
    "    name = path.name\n",
    "    img = cv2.imread(str(superstructures_train_image_path / name))\n",
    "    mask = cv2.imread(str(superstructures_train_label_path / name))\n",
    "\n",
    "    cv2.imwrite(str(superstructures_aug_train_image_path / name), img)\n",
    "    cv2.imwrite(str(superstructures_aug_train_label_path / name), mask)\n",
    "    \n",
    "    img, mask = process_pair(img, mask, correct=False)\n",
    "    \n",
    "    cv2.imwrite(str(superstructures_aug_train_image_path / name.replace('.png', '_transform.png')), img)\n",
    "    cv2.imwrite(str(superstructures_aug_train_label_path / name.replace('.png', '_transform.png')), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd2190",
   "metadata": {},
   "source": [
    "## Processing Superstructure images at half size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14eae50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 1504/1504 [01:44<00:00, 14.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Factor to augment the data, or how much to increase the original dataset\n",
    "AUGMENT_FACTOR = 4\n",
    "path_list = list(superstructures_train_image_path.glob('*.png'))\n",
    "path_list = multiply_list_float(path_list, AUGMENT_FACTOR)\n",
    "\n",
    "# Iterate every 4 images to get also lower resolution images\n",
    "for i in tqdm(range(0, len(path_list), 4)):\n",
    "    name_1 = path_list[i].name\n",
    "    name_2 = path_list[i+1].name\n",
    "    name_3 = path_list[i+2].name\n",
    "    name_4 = path_list[i+3].name\n",
    "    \n",
    "    img_1 = cv2.imread(str(superstructures_train_image_path / name_1))\n",
    "    img_2 = cv2.imread(str(superstructures_train_image_path / name_2))\n",
    "    img_3 = cv2.imread(str(superstructures_train_image_path / name_3))\n",
    "    img_4 = cv2.imread(str(superstructures_train_image_path / name_4))\n",
    "    mask_1 = cv2.imread(str(superstructures_train_label_path / name_1))\n",
    "    mask_2 = cv2.imread(str(superstructures_train_label_path / name_2))\n",
    "    mask_3 = cv2.imread(str(superstructures_train_label_path / name_3))\n",
    "    mask_4 = cv2.imread(str(superstructures_train_label_path / name_4))\n",
    "    \n",
    "    img = concat_images(img_1, img_2, img_3, img_4, 0.5)\n",
    "    mask = concat_images(mask_1, mask_2, mask_3, mask_4, 0.5)\n",
    "\n",
    "    cv2.imwrite(str(superstructures_aug_train_image_path / (str(i) + '_concat.png')), img)\n",
    "    cv2.imwrite(str(superstructures_aug_train_label_path / (str(i) + '_concat.png')), mask)\n",
    "    \n",
    "    img, mask = process_pair(img, mask, correct=False)\n",
    "    \n",
    "    cv2.imwrite(str(superstructures_aug_train_image_path / (str(i) + '_concat_transform.png')), img)\n",
    "    cv2.imwrite(str(superstructures_aug_train_label_path / (str(i) + '_concat_transform.png')), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfadb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
